{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is TensorFlow?\n",
    "\n",
    "TensorFlow is an open source liberary that is mainly used for machine learning and neural neworks. \n",
    "\n",
    "It works using GPUs and interactive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax:\n",
    "- tf.nn.softmax\n",
    "- A form of regression that assigns a probablilty to an object being one of many things- very good at classifying \n",
    "- The final step in most TensorFlow models is a softmax regression\n",
    "- It has two steps: adding up the evidence of the input being in a certian class\n",
    "    - converting the evidence into probablities \n",
    "    - exponentiating inpunts then normalizes them\n",
    "- see more about softmax here: (http://neuralnetworksanddeeplearning.com/chap3.html#softmax) it is really important to understand softmax as almost everything in TensorFlow as a component of softmax\n",
    "- a softmax, as do other common tensorflow equations, use weights and baises (explained below)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Terms and techniques:\n",
    "\n",
    "Cross entropy distance \n",
    "\n",
    "variable \n",
    "   - A modifiable tensor that can be used and modified by tensorflow-- call by using tf.Variable\n",
    "   - Before they can be used in a session they need to be initialized \n",
    "       - initializing takes the initial values that have already been specified and assigns them to  each variable \n",
    "   - Weights & biases are the two main types of variables used in TF, these are learnable parameters of the model that do not need to be provided before training, the model can adjust them\n",
    "   - Biases:\n",
    "       - extra evdience in our model that states that somethings are more likely to happen than others\n",
    "placeholder\n",
    "   - A value that is inputted later in the code for tensorflow to run a computation with\n",
    "   - important that shapes of the placeholders are the right size\n",
    "   - the value must be fed using the feed_dict function during a running session\n",
    "\n",
    "Dropout:\n",
    "   - applied before the readout layer the dropout\n",
    "   - used during training only and turned off during testing\n",
    "   - dropout removes a percent of neurons at random per run, the outputs of the other neurons are increased to compinsate \n",
    "   - \n",
    "session:\n",
    "\n",
    "Tensor:\n",
    "   - the unit of data in TensorFlow, it consists of a set of values shaped into an array of n number of dimensions\n",
    "   - a tensor's rank is determined by the number of dimensions\n",
    "\n",
    "ReLU (Rectified Linear Unit): \n",
    "   - closer model to the human neuron, zero for all negative values then linearly increaes for positive values\n",
    "   - \n",
    "\n",
    "bottleneck:\n",
    "   -  the layer right before the final output layer that does the classification-- has the softmax in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Training Models ***\n",
    "- What does that mean?\n",
    "    - define what it means for the model to be bad (the loss) and try to do the opposite\n",
    "     - to do this the \"cross-entropy\" distance or distance from the model to the disired outcome is calculated \n",
    "- By using the cross-entropy distance \n",
    "- Cross-entropy: Average length of of a message from q(x) usign code for p(x). It gives us a way to express how different two probablilty distributions are. The more diffferent the larger the cross-entropy will be.\n",
    "- Want a small learning rate as TensorFlow is actually doing a gradient calcuation and too large of a learnign rate will get you know where. \n",
    "    - In fact, the ideal learning rate model decays over time\n",
    "    - Two recommended learning rate optimizers are tf.train.AdagradientOptimizer and tf.train.AdamOptimizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided Optimizing Algorimths:\n",
    "- Gradident Descent\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layers\n",
    "\n",
    "Part of deep networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other machine learning terms:\n",
    "- transfering learning:\n",
    "    - taking a model that has been trained on one problem and retraining it on a similar one, this is faster than doing deep learnign from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful Hints/Tips of TensorFlow:\n",
    "- all variables need to be initialized at the start of a training session otherwise they could still be holding their values from the last session\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
